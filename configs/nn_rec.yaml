hydra:
  run:
    dir: ./exp/neural-net/training
  sweep:
    dir: ./exp/neural-net/training
    subdir: ${hydra.job.num}_${hydra.job.override_dirname}
  job:
    chdir: true

defaults:
  - nn@model: model
  - nn/optimizer@optimizer: adamw
  - nn/scheduler@scheduler: reduce_plateau
  - nn/loss@loss: triplet
  - _self_

data_dir: ./exp/neural-net/data
feature_dir: ./exp/neural-net/features-processed

train_params:
  train_size: 0.8
  batch_size: 30_000
  epochs: 20

{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "n2nirnt4f5jsdvrilebmp",
        "id": "XJw50plyv1bR"
      },
      "source": [
        "# Коллаборативная фильтрация"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "u8beyxhgmramqk69fct3an",
        "id": "3gt9TUqpv1bS"
      },
      "source": [
        "## Основная идея\n",
        "Как понять, что пользователю $u$ нужно показать айтем $i$?\n",
        "1. Если $u$ понравился айтем, похожий на $i$, то можно предположить, что ему понравится $i$.\n",
        "2. Если ему не понравился айтем, похожий на $i$, ему, вероятно, не понравится и $i$.\n",
        "\n",
        "Таким образом, идея состоит в том, чтобы посмотреть, насколько понравились $u$ айтемы, похожие на $i$."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "2p3yhx2iuo4pnd523k99",
        "id": "80StAkPXv1bT"
      },
      "source": [
        "## Item-to-item collaborative filtering\n",
        "\n",
        "Реализуем на семинаре следующую вариацию item-to-item метода.\n",
        "1. Пусть $U_i$ &mdash; множество пользователей, оценивших $i$. Определим, как мы будем определять похожести между айтемами. Определим похожести между айтемами, как\n",
        "$$\n",
        "         w(i, j) = \\frac{\\sum_{u\\in U_i \\cap U_j}(r_{u,i}-\\bar{r}_u)(r_{u,j}-\\bar{r}_u)}{\\sqrt{\\sum_{u\\in U_i \\cap U_j} (r_{u,i}-\\bar{r}_u)^2}\\sqrt{\\sum_{u\\in U_i \\cap U_j} (r_{u,j}-\\bar{r}_u)^2}}.\n",
        "$$\n",
        "Обозначим за $S_k^{(i)}$ множество из $k$ наиболее близких к $i$ айтемов.\n",
        "   \n",
        "2. Пользователю $u$, оценившему множество айтемов $I_u$, будем рекомендовать $N$ наиболее подходящих ему айтемов. Для этого,\n",
        "- В качестве кандидатов на попадание в топ возьмем айтемы $$C = \\bigcup_{i \\in I_u} S_k^{(i)} \\setminus I_u.$$\n",
        "- Для кандидатов $c \\in C$ определим похожесть $c$ на историю пользователя $I_u$, как\n",
        "\\begin{equation}\n",
        " w(c,I_u) = \\sum_{i\\in I_u} w_{c,i}.\n",
        "\\end{equation}\n",
        "- Вернем в качестве результата $N$ айтемов $c \\in C$ с максимальной величиной $w(c, I_u)$.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "tmnyods6w1zik992944cn",
        "id": "Xd0esHr4v1bU"
      },
      "source": [
        "### Import useful requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import cupy\n",
        "from cupy import sparse as cusparse\n",
        "from scipy import sparse\n",
        "import numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "cellId": "p0ltx0obd6ouwa94dtend",
        "id": "3DsS6bkwv1bW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from recs_utils.load_data import MovieLens100K\n",
        "from recs_utils.matrix_ops import interactions_to_csc_matrix\n",
        "from recs_utils.cuda import ADJUSTED_COSINE_SIM_BETWEEN_ITEMS, get_grid_thread_size"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "9uylwuwzrjree6751a94ke",
        "id": "IVifyiz-v1bX"
      },
      "source": [
        "### Загрузка датасета"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ei8jN45Rr8dw"
      },
      "source": [
        "Для применения методов будем использовать датасет Movielens. Он представляет из себя оценки, которые пользователи поставили просмотренным фильмам и небольшие описания самих фильмов.\n",
        "\n",
        "Для удобства изучения разных алгоритмов исследовательская группа, которая занимается разработкой датасета, подготовила данные разного объёма: 100к рейтингов, 1М, 10М, 20М. В этой работе мы будем пользоваться самым маленьким.\n",
        "\n",
        "https://www.kaggle.com/datasets/prajitdatta/movielens-100k-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path(\"data/movielens/ml-100k\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "interactions = MovieLens100K.load_interactions(str(data_dir / \"u.data\"))\n",
        "items = MovieLens100K.load_items(str(data_dir / \"u.item\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>rating</th></tr><tr><td>f32</td></tr></thead><tbody><tr><td>1.0</td></tr><tr><td>2.0</td></tr><tr><td>3.0</td></tr><tr><td>4.0</td></tr><tr><td>5.0</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (5, 1)\n",
              "┌────────┐\n",
              "│ rating │\n",
              "│ ---    │\n",
              "│ f32    │\n",
              "╞════════╡\n",
              "│ 1.0    │\n",
              "│ 2.0    │\n",
              "│ 3.0    │\n",
              "│ 4.0    │\n",
              "│ 5.0    │\n",
              "└────────┘"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interactions.select(pl.col(\"rating\").unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th></tr><tr><td>u32</td><td>u32</td><td>f32</td></tr></thead><tbody><tr><td>1</td><td>1</td><td>5.0</td></tr><tr><td>1</td><td>2</td><td>3.0</td></tr><tr><td>1</td><td>3</td><td>4.0</td></tr><tr><td>1</td><td>4</td><td>3.0</td></tr><tr><td>1</td><td>5</td><td>3.0</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (5, 3)\n",
              "┌─────────┬─────────┬────────┐\n",
              "│ user_id ┆ item_id ┆ rating │\n",
              "│ ---     ┆ ---     ┆ ---    │\n",
              "│ u32     ┆ u32     ┆ f32    │\n",
              "╞═════════╪═════════╪════════╡\n",
              "│ 1       ┆ 1       ┆ 5.0    │\n",
              "│ 1       ┆ 2       ┆ 3.0    │\n",
              "│ 1       ┆ 3       ┆ 4.0    │\n",
              "│ 1       ┆ 4       ┆ 3.0    │\n",
              "│ 1       ┆ 5       ┆ 3.0    │\n",
              "└─────────┴─────────┴────────┘"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interactions.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(interactions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 2)\n",
            "┌─────────┬───────────────────┐\n",
            "│ item_id ┆ title             │\n",
            "│ ---     ┆ ---               │\n",
            "│ u32     ┆ str               │\n",
            "╞═════════╪═══════════════════╡\n",
            "│ 1       ┆ Toy Story (1995)  │\n",
            "│ 2       ┆ GoldenEye (1995)  │\n",
            "│ 3       ┆ Four Rooms (1995) │\n",
            "│ 4       ┆ Get Shorty (1995) │\n",
            "│ 5       ┆ Copycat (1995)    │\n",
            "└─────────┴───────────────────┘\n"
          ]
        }
      ],
      "source": [
        "with pl.Config() as config:\n",
        "    config.set_fmt_str_lengths(100)\n",
        "    print(items.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1682"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_direct_and_inv_mapping(interactions: pl.DataFrame, col_name: str):\n",
        "    inv_mapping = dict(enumerate(interactions.select(\n",
        "            pl.col(col_name).unique().sort()).to_series()))\n",
        "    direct_mapping = {v: k for k, v in inv_mapping.items()}\n",
        "\n",
        "    return direct_mapping, inv_mapping"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "72xbmj2k4qqz2ybj3odc",
        "id": "yruhwBKkv1bX"
      },
      "source": [
        "### Предобработка датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "cellId": "pbcolehyqc90qf4r6u6n9",
        "id": "tLmj2sWuv1bY"
      },
      "outputs": [],
      "source": [
        "# create the encoder\n",
        "user_mapping, inv_user_mapping = get_direct_and_inv_mapping(interactions, \"user_id\")\n",
        "item_mapping, inv_item_mapping = get_direct_and_inv_mapping(interactions, \"item_id\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "xs72r2xxg2j9vcam9ezl8",
        "id": "da46j6zMv1bY"
      },
      "source": [
        "## Реализация алгоритма"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "hseep36n118brjb0uuee4b",
        "id": "8-IZJfnWv1bZ"
      },
      "source": [
        "### Шаг 1. Вычислить похожести между айтемами"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NgTJIeh4uCrP"
      },
      "source": [
        "#### adjustied cosine similarity\n",
        "\n",
        "Вспомним, что каждый айтем можно представить как вектор оценок пользователей, тогда для оценки похожести можно использовать:\n",
        "1. Косинусное расстояние\n",
        "2. Ajusted Cosine Similarity\n",
        "3. Евклидово расстояние\n",
        "4. Манхэттенское расстояние\n",
        "5. Коэффициент Жаккара"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C1rSNwK7v1bb"
      },
      "source": [
        "\n",
        "\n",
        "В item-based рекомендациях к-т adjustied cosine similarity доказал свою эффективность, поэтому будем использовать его. Схожесть между айтемами $i$ и $j$ считается по формуле:\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "wfd7z0lf61z0i6ur83d2",
        "id": "-2OkygNZv1bb"
      },
      "source": [
        "\\begin{equation}\n",
        " w_{i,j}= \\frac{\\sum_{u\\in U}(r_{u,i}-\\bar{r}_u)(r_{u,j}-\\bar{r}_u)}{\\sqrt{\\sum_{u\\in U} (r_{u,i}-\\bar{r}_u)^2}\\sqrt{\\sum_{u\\in U} (r_{u,j}-\\bar{r}_u)^2}}.\n",
        "\\end{equation}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "qkjdwv480rbe8p6xoqf8hb",
        "id": "2PtDXI6Iv1bZ"
      },
      "source": [
        "Итак, чтобы вычислить похожесть между айтемами $i$ и $j$, нужно\n",
        "\n",
        "1. Выявить всех пользователей, которые оценили оба айтема, т.е. $U_i \\cap U_j$;\n",
        "2. Нормализовать рейтинги айтемов $i$ и $j$;\n",
        "3. Посчитать похожесть между векторами общих рейтингов $i$ и $j$.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "egzC9jh5v1bZ"
      },
      "source": [
        "Проведём подготовительную работу и нормализуем рейтинги всех пользователей:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "cellId": "9ipkwjqjb6fvn2pp6wb5fq",
        "id": "e325DrNhv1bZ"
      },
      "outputs": [],
      "source": [
        "def normalize(ratings: pl.DataFrame) -> pl.DataFrame:\n",
        "    \"\"\"\n",
        "    Нормализует рейтинги по пользователям. Из каждого рейтинга вычитает средний рейтинг по пользователю.\n",
        "    ratings: таблица рейтингов\n",
        "    \n",
        "    Возвращает: \n",
        "        Таблица, содержащая все колонки таблицы `ratings` и колонку `norm_rating` с нормализованными рейтингами.\n",
        "    \"\"\"\n",
        "    return ratings.lazy().join(\n",
        "        ratings.lazy().select(pl.col(\"user_id\"), pl.col(\"rating\")).groupby(\"user_id\").agg(\n",
        "        [\n",
        "            pl.mean(\"rating\").alias(\"mean_user_rating\")\n",
        "        ]\n",
        "        ),\n",
        "        on=\"user_id\",\n",
        "        how=\"inner\").with_columns(\n",
        "        (pl.col(\"rating\") - pl.col(\"mean_user_rating\")).alias(\"norm_rating\")\n",
        "        ).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "isTOB7asv1ba"
      },
      "outputs": [],
      "source": [
        "def test_normalize():\n",
        "    test_df = pl.DataFrame({\n",
        "        \"user_id\": [0, 0, 0, 1, 1],\n",
        "        \"item_id\": [0, 1, 2, 1, 3],\n",
        "        \"rating\": [2, 2, 5, 5, 5],\n",
        "    })\n",
        "    \n",
        "    expected = pl.DataFrame({\n",
        "        \"user_id\": [0, 0, 0, 1, 1],\n",
        "        \"item_id\": [0, 1, 2, 1, 3],\n",
        "        \"rating\": [2, 2, 5, 5, 5],\n",
        "        \"norm_rating\": [-1, -1, 2, 0, 0]\n",
        "    })    \n",
        "    \n",
        "    assert test_df.shape[0] == expected.shape[0], \"Number of user-item interactions is different\"\n",
        "    assert test_df.shape[1] + 1 == expected.shape[1], \"Number of columns is incorrect\"\n",
        "    assert normalize(test_df).select(pl.all().exclude(\"mean_user_rating\")).frame_equal(expected), \"Result is incorrect\"\n",
        "    \n",
        "test_normalize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "cellId": "py2xe668c2bq26cxnvlqhn",
        "id": "7l7BkAB9v1ba",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "norm_ratings = normalize(interactions)\n",
        "norm_ratings.head()\n",
        "del interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "centered_rating_matrix = interactions_to_csc_matrix(norm_ratings, users_mapping=user_mapping, items_mapping=item_mapping, weight_col=\"norm_rating\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compression ratio:  0.9369533063577546\n"
          ]
        }
      ],
      "source": [
        "print(\"Compression ratio: \", 1 - centered_rating_matrix.getnnz() / (centered_rating_matrix.shape[0] * centered_rating_matrix.shape[1]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EzCNpi1kv1ba"
      },
      "source": [
        "Итак, мы вычислили средний рейтинг для каждого пользователя. Теперь мы готовы к вычислению похожестей айтемов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adjusted_cosine_sim_gpu(csc_matrix: sparse.csc_matrix, device: cupy.cuda.Device, min_estimation: int):\n",
        "    csc_matrix_gpu = cusparse.csc_matrix(csc_matrix)\n",
        "    num_items = csc_matrix_gpu.shape[1]\n",
        "    grid_size, thread_size = get_grid_thread_size(device, num_items)\n",
        "    cuda_dtype = cupy.float64\n",
        "    distances = cupy.zeros((num_items, num_items), dtype=cuda_dtype)  \n",
        "    ADJUSTED_COSINE_SIM_BETWEEN_ITEMS(grid_size, thread_size, \n",
        "                                  (cupy.uint(num_items), \n",
        "                                   cupy.uint(min_estimation),\n",
        "                                   csc_matrix_gpu.indptr.astype(cupy.uint), \n",
        "                                   csc_matrix_gpu.indices.astype(cupy.uint), \n",
        "                                   csc_matrix_gpu.data.astype(cuda_dtype), \n",
        "                                   distances))\n",
        "    \n",
        "    return cupy.asnumpy(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "with cupy.cuda.Device(0) as device:\n",
        "    rid_size, thread_size = get_grid_thread_size(device, centered_rating_matrix.shape[1])\n",
        "    distances = adjusted_cosine_sim_gpu(centered_rating_matrix, device, min_estimation=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# some difference because explicit numeric computing on the GPU with custom kernel may be unstable\n",
        "assert math.isclose(distances[0, 0], 1.0)\n",
        "assert math.isclose(distances[1, 2], 0.1069226, abs_tol=1e-7)\n",
        "assert math.isclose(distances[1, 3], 0.0555092, abs_tol=1e-7)\n",
        "assert math.isclose(distances[1, 5], -0.125509, abs_tol=1e-6)\n",
        "assert math.isclose(distances[1, 1431], 1.0)\n",
        "assert math.isclose(distances[4, 1123], 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sort_simil_with_neighs(similarities: np.ndarray):\n",
        "    sorted_sim = similarities.copy()\n",
        "    \n",
        "    np.fill_diagonal(sorted_sim, similarities.min() - 1)\n",
        "    neighbors = np.flip(np.argsort(sorted_sim, axis=1), axis=1)\n",
        "\n",
        "    for i in range(len(sorted_sim)):\n",
        "        sorted_sim[i] = sorted_sim[i][neighbors[i]]\n",
        "\n",
        "    assert neighbors.shape == sorted_sim.shape\n",
        "\n",
        "    return sorted_sim, neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "@numba.jit(signature_or_function=numba.void(\n",
        "        numba.uint32, \n",
        "        numba.uint32, \n",
        "        numba.uint32[:], \n",
        "        numba.uint32[:],\n",
        "        numba.double[:],\n",
        "        numba.double[:, :]\n",
        "        ),\n",
        "        nopython=True,\n",
        "        parallel=True)\n",
        "def cosine_sim_cpu(\n",
        "    num_items,\n",
        "    min_estimations,\n",
        "    csc_col_pointers,\n",
        "    csc_row_indices,\n",
        "    csc_values,\n",
        "    distance_matrix):\n",
        "    for item_i in numba.prange(num_items):\n",
        "        for item_j in numba.prange(item_i, num_items):\n",
        "            \n",
        "            if item_i == item_j:\n",
        "                distance_matrix[item_i, item_j] = 1.0\n",
        "                distance_matrix[item_j, item_i] = distance_matrix[item_i, item_j]\n",
        "                continue\n",
        "\n",
        "            start_i = csc_col_pointers[item_i]\n",
        "            end_i = csc_col_pointers[item_i + 1]\n",
        "\n",
        "            start_j = csc_col_pointers[item_j]\n",
        "            end_j = csc_col_pointers[item_j + 1]\n",
        "\n",
        "            num_estimation = 0\n",
        "\n",
        "            while start_i < end_i and start_j < end_j:\n",
        "                if csc_row_indices[start_i] == csc_row_indices[start_j]:\n",
        "                    num_estimation += 1\n",
        "                    start_i += 1\n",
        "                    start_j += 1\n",
        "                elif csc_row_indices[start_i] < csc_row_indices[start_j]:\n",
        "                    start_i += 1\n",
        "                else:\n",
        "                    start_j += 1\n",
        "\n",
        "            if num_estimation < min_estimations:\n",
        "                distance_matrix[item_i, item_j] = 0.0\n",
        "                distance_matrix[item_j, item_i] = distance_matrix[item_i, item_j]\n",
        "                continue\n",
        "\n",
        "            start_i = csc_col_pointers[item_i]\n",
        "            start_j = csc_col_pointers[item_j]\n",
        "\n",
        "            num = 0.0\n",
        "            denum_i = 0.0\n",
        "            denum_j = 0.0\n",
        "\n",
        "            while start_i < end_i and start_j < end_j:\n",
        "                if csc_row_indices[start_i] == csc_row_indices[start_j]:\n",
        "                    num += csc_values[start_i] * csc_values[start_j]\n",
        "                    denum_i += csc_values[start_i] ** 2\n",
        "                    denum_j += csc_values[start_j] ** 2\n",
        "                    start_i += 1\n",
        "                    start_j += 1\n",
        "                elif csc_row_indices[start_i] < csc_row_indices[start_j]:\n",
        "                    start_i += 1\n",
        "                else:\n",
        "                    start_j += 1\n",
        "\n",
        "            if np.isclose(denum_i, 0.0):\n",
        "                inv_denum_i = 0.0\n",
        "            else:\n",
        "                inv_denum_i = 1 / np.sqrt(denum_i)\n",
        "            \n",
        "            if np.isclose(denum_j, 0.0):\n",
        "                inv_denum_j = 0.0\n",
        "            else:\n",
        "                inv_denum_j = 1 / np.sqrt(denum_j)\n",
        "\n",
        "            distance_matrix[item_i, item_j] = num * inv_denum_j * inv_denum_i\n",
        "            distance_matrix[item_j, item_i] = distance_matrix[item_i, item_j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "distance_cpu = np.zeros((centered_rating_matrix.shape[1], centered_rating_matrix.shape[1]), dtype=np.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "cosine_sim_cpu(\n",
        "    centered_rating_matrix.shape[1],\n",
        "    0,\n",
        "    centered_rating_matrix.indptr.astype(np.uint32),\n",
        "    centered_rating_matrix.indices.astype(np.uint32),\n",
        "    centered_rating_matrix.data.astype(np.float64),\n",
        "    distance_cpu\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1.0"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distance_cpu[0, 1475]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.allclose(distances, distance_cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_sim, neighbors = sort_simil_with_neighs(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1.0"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distances[0, 1475]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xzZTgr1Wv1bd"
      },
      "source": [
        "Посмотрим глазами на списки соседей, которые мы получили."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_neighs(item: pl.DataFrame, similarities: np.ndarray, neighbors: np.ndarray, inv_item_mapping: dict, k: int = 5):\n",
        "    sim = similarities[:, :k].reshape(-1)\n",
        "    neighs = neighbors[:, :k].reshape(-1)\n",
        "\n",
        "    most_sim_items = pl.DataFrame(\n",
        "        {\n",
        "            \"item_id\": np.arange(len(similarities)).repeat(k),\n",
        "            \"sim\": sim,\n",
        "            \"sim_item_id\": neighs\n",
        "        },\n",
        "        schema={\"item_id\": item.schema[\"item_id\"], \"sim_item_id\": item.schema[\"item_id\"], \"sim\": pl.Float32}\n",
        "    ).with_columns(\n",
        "        pl.col(\"sim_item_id\").apply(inv_item_mapping.get).alias(\"sim_item_id\").cast(item.schema[\"item_id\"]),\n",
        "        pl.col(\"item_id\").apply(inv_item_mapping.get).alias(\"item_id\").cast(item.schema[\"item_id\"])\n",
        "    )\n",
        "\n",
        "    return most_sim_items.join(item, left_on=\"sim_item_id\", right_on=\"item_id\", how=\"inner\").join(\n",
        "        item.select(pl.col(\"item_id\"), pl.col(\"title\").alias(\"orig_title\")), on=\"item_id\", how=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "most_sim_items = show_neighs(items, sorted_sim, neighbors, inv_item_mapping, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 5)\n",
            "┌─────────┬─────────────┬─────┬────────────────────────────────┬──────────────────┐\n",
            "│ item_id ┆ sim_item_id ┆ sim ┆ title                          ┆ orig_title       │\n",
            "│ ---     ┆ ---         ┆ --- ┆ ---                            ┆ ---              │\n",
            "│ u32     ┆ u32         ┆ f64 ┆ str                            ┆ str              │\n",
            "╞═════════╪═════════════╪═════╪════════════════════════════════╪══════════════════╡\n",
            "│ 1       ┆ 1657        ┆ 1.0 ┆ Target (1995)                  ┆ Toy Story (1995) │\n",
            "│ 1       ┆ 1450        ┆ 1.0 ┆ Golden Earrings (1947)         ┆ Toy Story (1995) │\n",
            "│ 1       ┆ 1261        ┆ 1.0 ┆ Run of the Country, The (1995) ┆ Toy Story (1995) │\n",
            "│ 1       ┆ 1493        ┆ 1.0 ┆ Modern Affair, A (1995)        ┆ Toy Story (1995) │\n",
            "│ 1       ┆ 1627        ┆ 1.0 ┆ Wife, The (1995)               ┆ Toy Story (1995) │\n",
            "└─────────┴─────────────┴─────┴────────────────────────────────┴──────────────────┘\n",
            "shape: (5, 5)\n",
            "┌─────────┬─────────────┬─────┬──────────────────────────────────────┬─────────────────────────────┐\n",
            "│ item_id ┆ sim_item_id ┆ sim ┆ title                                ┆ orig_title                  │\n",
            "│ ---     ┆ ---         ┆ --- ┆ ---                                  ┆ ---                         │\n",
            "│ u32     ┆ u32         ┆ f64 ┆ str                                  ┆ str                         │\n",
            "╞═════════╪═════════════╪═════╪══════════════════════════════════════╪═════════════════════════════╡\n",
            "│ 1682    ┆ 704         ┆ 1.0 ┆ House of the Spirits, The (1993)     ┆ Scream of Stone (Schrei aus │\n",
            "│         ┆             ┆     ┆                                      ┆ Stein) (1991)               │\n",
            "│ 1682    ┆ 249         ┆ 1.0 ┆ Austin Powers: International Man of  ┆ Scream of Stone (Schrei aus │\n",
            "│         ┆             ┆     ┆ Mystery (1997)                       ┆ Stein) (1991)               │\n",
            "│ 1682    ┆ 237         ┆ 1.0 ┆ Jerry Maguire (1996)                 ┆ Scream of Stone (Schrei aus │\n",
            "│         ┆             ┆     ┆                                      ┆ Stein) (1991)               │\n",
            "│ 1682    ┆ 66          ┆ 1.0 ┆ While You Were Sleeping (1995)       ┆ Scream of Stone (Schrei aus │\n",
            "│         ┆             ┆     ┆                                      ┆ Stein) (1991)               │\n",
            "│ 1682    ┆ 239         ┆ 1.0 ┆ Sneakers (1992)                      ┆ Scream of Stone (Schrei aus │\n",
            "│         ┆             ┆     ┆                                      ┆ Stein) (1991)               │\n",
            "└─────────┴─────────────┴─────┴──────────────────────────────────────┴─────────────────────────────┘\n"
          ]
        }
      ],
      "source": [
        "with pl.Config() as cfg:\n",
        "    cfg.set_fmt_str_lengths(200)\n",
        "    print(most_sim_items.head())\n",
        "    print(most_sim_items.tail())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PQfUUfdnKxuS"
      },
      "source": [
        "Как вам кажется, получились ли у нас хорошие результаты? Что объединяет нерелевантные айтемы из топов по похожестям?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "with cupy.cuda.Device(0) as device:\n",
        "    rid_size, thread_size = get_grid_thread_size(device, centered_rating_matrix.shape[1])\n",
        "    distances = adjusted_cosine_sim_gpu(centered_rating_matrix, device, min_estimation=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "0o_KjzkjrPJT"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(distances[1, 1431], 0)\n",
        "assert np.isclose(distances[1, 17], 0)\n",
        "assert np.isclose(distances[4, 1123], 0)\n",
        "assert np.isclose(distances[914, 1681], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Kbx1ElEPLFF6"
      },
      "outputs": [],
      "source": [
        "sorted_sim, neighbors = sort_simil_with_neighs(distances)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z4QXqO2a9n9n"
      },
      "source": [
        "Посмотрим, что получилось теперь:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Q6n8kbeg9nS9"
      },
      "outputs": [],
      "source": [
        "most_sim_items = show_neighs(items, sorted_sim, neighbors, inv_item_mapping, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 5)\n",
            "┌─────────┬─────────────┬──────────┬──────────────────────────────┬──────────────────┐\n",
            "│ item_id ┆ sim_item_id ┆ sim      ┆ title                        ┆ orig_title       │\n",
            "│ ---     ┆ ---         ┆ ---      ┆ ---                          ┆ ---              │\n",
            "│ u32     ┆ u32         ┆ f64      ┆ str                          ┆ str              │\n",
            "╞═════════╪═════════════╪══════════╪══════════════════════════════╪══════════════════╡\n",
            "│ 1       ┆ 921         ┆ 0.538191 ┆ Farewell My Concubine (1993) ┆ Toy Story (1995) │\n",
            "│ 1       ┆ 500         ┆ 0.511432 ┆ Fly Away Home (1996)         ┆ Toy Story (1995) │\n",
            "│ 1       ┆ 923         ┆ 0.506015 ┆ Raise the Red Lantern (1991) ┆ Toy Story (1995) │\n",
            "│ 1       ┆ 489         ┆ 0.461624 ┆ Notorious (1946)             ┆ Toy Story (1995) │\n",
            "│ 1       ┆ 1152        ┆ 0.453082 ┆ In Love and War (1996)       ┆ Toy Story (1995) │\n",
            "└─────────┴─────────────┴──────────┴──────────────────────────────┴──────────────────┘\n",
            "shape: (5, 5)\n",
            "┌─────────┬─────────────┬─────┬───────────────────────────┬────────────────────────────────────┐\n",
            "│ item_id ┆ sim_item_id ┆ sim ┆ title                     ┆ orig_title                         │\n",
            "│ ---     ┆ ---         ┆ --- ┆ ---                       ┆ ---                                │\n",
            "│ u32     ┆ u32         ┆ f64 ┆ str                       ┆ str                                │\n",
            "╞═════════╪═════════════╪═════╪═══════════════════════════╪════════════════════════════════════╡\n",
            "│ 1682    ┆ 841         ┆ 0.0 ┆ Glimmer Man, The (1996)   ┆ Scream of Stone (Schrei aus Stein) │\n",
            "│         ┆             ┆     ┆                           ┆ (1991)                             │\n",
            "│ 1682    ┆ 578         ┆ 0.0 ┆ Demolition Man (1993)     ┆ Scream of Stone (Schrei aus Stein) │\n",
            "│         ┆             ┆     ┆                           ┆ (1991)                             │\n",
            "│ 1682    ┆ 554         ┆ 0.0 ┆ Waterworld (1995)         ┆ Scream of Stone (Schrei aus Stein) │\n",
            "│         ┆             ┆     ┆                           ┆ (1991)                             │\n",
            "│ 1682    ┆ 555         ┆ 0.0 ┆ White Man's Burden (1995) ┆ Scream of Stone (Schrei aus Stein) │\n",
            "│         ┆             ┆     ┆                           ┆ (1991)                             │\n",
            "│ 1682    ┆ 556         ┆ 0.0 ┆ Wild Bill (1995)          ┆ Scream of Stone (Schrei aus Stein) │\n",
            "│         ┆             ┆     ┆                           ┆ (1991)                             │\n",
            "└─────────┴─────────────┴─────┴───────────────────────────┴────────────────────────────────────┘\n"
          ]
        }
      ],
      "source": [
        "with pl.Config() as cfg:\n",
        "    cfg.set_fmt_str_lengths(200)\n",
        "    print(most_sim_items.head())\n",
        "    print(most_sim_items.tail())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "hseep36n118brjb0uuee4b",
        "id": "TyLvzZfBv1bd"
      },
      "source": [
        "### Шаг 2. Выбрать топ рекомендаций для пользователя"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oXxnirjyv1be"
      },
      "source": [
        "Теперь, когда для каждого айтема есть список похожих, научимся формировать рекомендацию для пользователя.\n",
        "\n",
        "#### Отбор кандидатов\n",
        "\n",
        "1. Для каждого айтема из истории соберём сет из k самых похожих айтемов\n",
        "2. Объединим полученные сеты\n",
        "3. Уберём из полученного множества те айтемы, с которыми пользователь уже взаимодействовал"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "cellId": "g318akv7ffe8fg0iufcoxw",
        "id": "cwWDrpN5v1be"
      },
      "outputs": [],
      "source": [
        "def candidate_items(interactions: pl.DataFrame, \n",
        "                    user_id: int, \n",
        "                    k: int, \n",
        "                    sorted_sim: np.ndarray, \n",
        "                    sorted_neighbors: np.ndarray, \n",
        "                    item_mapping: dict, \n",
        "                    inv_item_mapping: dict):\n",
        "    \"\"\"\n",
        "    np_ratings: массив, каждый элемент которого является набором (user_id, item_id, rating, norm_rating)\n",
        "    userid: id пользователя, для которого генерируются кандидаты\n",
        "    k: количество кандидатов с каждого айтема из истории\n",
        "    \n",
        "    Возвращает \n",
        "        1. массив user_item_ids с id фильмов, просмотренных пользователем\n",
        "        2. массив айтемов, близких к айтемам из истории пользователя\n",
        "    \"\"\"\n",
        "\n",
        "    item_ids_hist = interactions.lazy().filter(pl.col(\"user_id\") == user_id).select(pl.col(\"item_id\").unique()).collect().to_series()\n",
        "    zero_item_indices = item_ids_hist.apply(item_mapping.get)\n",
        "\n",
        "    uniq_item_ids = np.unique(sorted_neighbors[zero_item_indices, :k].reshape(-1))\n",
        "    \n",
        "    return item_ids_hist, np.array(tuple(map(inv_item_mapping.get, np.setdiff1d(uniq_item_ids, item_ids_hist))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "cellId": "8tx2ejas3twa354gtswotm",
        "id": "RvwdB11Jv1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество просмотренных фильмов пользователя 1: 272\n",
            "Количество кандидатов для пользователя 1: 1410\n"
          ]
        }
      ],
      "source": [
        "user_item_ids, u_candidates = candidate_items(norm_ratings, 1, sorted_sim.shape[1], sorted_sim, neighbors, item_mapping, inv_item_mapping)\n",
        "\n",
        "print('Количество просмотренных фильмов пользователя 1:', len(user_item_ids))\n",
        "print('Количество кандидатов для пользователя 1:', len(u_candidates))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1UMBD0_lv1be"
      },
      "outputs": [],
      "source": [
        "user_item_ids_test, u_candidates_test = candidate_items(norm_ratings, 1, sorted_sim.shape[1], sorted_sim, neighbors, item_mapping, inv_item_mapping)\n",
        "assert len(user_item_ids_test) == 272\n",
        "assert len(u_candidates_test) == 1410\n",
        "\n",
        "user_item_ids_test, u_candidates_test = candidate_items(norm_ratings, 50, sorted_sim.shape[1], sorted_sim, neighbors, item_mapping, inv_item_mapping)\n",
        "\n",
        "assert len(user_item_ids_test) == 24\n",
        "assert len(u_candidates_test) == 1658\n",
        "\n",
        "user_item_ids_test, u_candidates_test = candidate_items(norm_ratings, 942, sorted_sim.shape[1], sorted_sim, neighbors, item_mapping, inv_item_mapping)\n",
        "assert len(user_item_ids_test) == 79\n",
        "assert len(u_candidates_test) == 1603\n",
        "\n",
        "del user_item_ids_test, u_candidates_test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "2t3p1thkyiwapp43oni90l",
        "id": "Ep4AmKdOv1be"
      },
      "source": [
        "#### Вычисление похожести между кандидатом и множеством айтемов из истории пользователя u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "cellId": "azxskh7983hfjdsjtyzifq",
        "id": "K8GCR42Wv1bf"
      },
      "outputs": [],
      "source": [
        "def similarity_with_user_items(\n",
        "                            interactions: pl.DataFrame,\n",
        "                            user_id: int,\n",
        "                            item_id: int, \n",
        "                            user_item_ids: np.ndarray,\n",
        "                            distance_matrix: np.ndarray, \n",
        "                            item_mapping: dict) -> float:\n",
        "    \"\"\"\n",
        "    item_id: id айтема-кандидата, для которого считается похожесть с историей пользователя\n",
        "    user_item_ids: массив id фильмов, просмотренных пользователем\n",
        "    similarities: массив похожестей айтемов\n",
        "    neighbors: массив соседей для всех айтемов\n",
        "    \n",
        "    Возвращает число – похожесть айтема на историю пользователя.\n",
        "    \"\"\"\n",
        "\n",
        "    similiarities = distance_matrix[item_mapping[item_id], list(map(item_mapping.get, user_item_ids))]\n",
        "\n",
        "    items_info = pl.DataFrame(\n",
        "        {\n",
        "            \"item_id\": user_item_ids,\n",
        "        },\n",
        "        schema={\"item_id\": interactions.schema[\"item_id\"]}\n",
        "    ).lazy().join(\n",
        "        interactions.filter((pl.col(\"user_id\") == user_id)).lazy(), on=\"item_id\", how=\"left\"\n",
        "    ).select(\n",
        "        pl.col(\"norm_rating\"),\n",
        "        pl.col(\"mean_user_rating\")\n",
        "    ).collect()\n",
        "\n",
        "    mean_user_rating = items_info.select(pl.col(\"mean_user_rating\").max())[0, 0]\n",
        "    centered_rating = items_info.select(pl.col(\"norm_rating\")).to_series().to_numpy()\n",
        "\n",
        "    norm = np.linalg.norm(similiarities, ord=1)\n",
        "\n",
        "    if math.isclose(norm, 0):\n",
        "        inv_norm = 0.0\n",
        "    else:\n",
        "        inv_norm = 1.0 / norm\n",
        "\n",
        "    return mean_user_rating + centered_rating.dot(similiarities) * inv_norm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "cellId": "2t3p1thkyiwapp43oni90l",
        "id": "BY9qaIOcv1bf"
      },
      "source": [
        "#### Ранжирование кандидатов по их похожестям на историю пользователя"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "cellId": "angr2yo0e4zk965hv14r",
        "id": "Gj3efZMqv1bf"
      },
      "outputs": [],
      "source": [
        "def rank_candidates(interactions: pl.DataFrame, user_id: int, candidates: np.ndarray, user_item_ids: np.ndarray, distance_matrix: np.ndarray, item_mapping: dict):\n",
        "    \"\"\"\n",
        "    candidates: массив id фильмов-кандидатов\n",
        "    user_item_ids: массив id фильмов, просмотренных пользователем\n",
        "    similarities: массив похожестей айтемов\n",
        "    neighbors: массив соседей для всех айтемов\n",
        "    \n",
        "    Возвращает массив tuple, где первый элемент – айди айтема, второй – похожесть на историю пользователя\n",
        "    \"\"\"\n",
        "    \n",
        "    # list of candidate items mapped to their corresponding similarities to user_item_ids\n",
        "    sims = [similarity_with_user_items(interactions, user_id, c, user_item_ids, distance_matrix, item_mapping) for c in candidates]\n",
        "    mapping = list(zip(candidates, sims))\n",
        "    ranked_candidates = sorted(mapping, key=lambda couple: couple[1], reverse=True)\n",
        "\n",
        "    return np.array(ranked_candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_id = 1\n",
        "\n",
        "user_item_ids_test, candidates_test = candidate_items(norm_ratings, user_id, sorted_sim.shape[1], sorted_sim, neighbors, item_mapping, inv_item_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "AJKMVQRcv1bf"
      },
      "outputs": [],
      "source": [
        "assert len(rank_candidates(norm_ratings, user_id, candidates_test, user_item_ids_test, distances, item_mapping)) == len(candidates_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ4M9NLhv1bf"
      },
      "source": [
        "## Соберём всё вместе"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4T6EHhfUv1bf"
      },
      "source": [
        "Теперь у нас есть всё, что нужно: отбор кандидатов, ранжирующая функция и мы готовы собрать весь пайплайн item-to-item рекомендаций."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "cellId": "xbxcbljvovnf3iolf27kw",
        "id": "iV9vTfbPv1bg"
      },
      "outputs": [],
      "source": [
        "def topn_recommendation(norm_ratings: pl.DataFrame, items: pl.DataFrame, user_id: int, distance_matrix: np.ndarray, sorted_sim: np.ndarray, neighbors: np.ndarray, item_mapping: dict, k=None, N=30):\n",
        "    \"\"\"\n",
        "    np_ratings: массив, каждый элемент которого является набором (user_id, item_id, rating, norm_rating)\n",
        "    userid: id пользователя, для которого генерируются кандидаты\n",
        "    similarities: массив похожестей айтемов\n",
        "    neighbors: массив соседей для всех айтемов\n",
        "    k: количество кандидатов на стадии отбора кандидатов\n",
        "    N: количество рекомендаций фильмов для пользователя\n",
        "    \n",
        "    Возвращает dataframe c рекомендацией top-N фильмов для пользователя userid.\n",
        "    \"\"\"\n",
        "    if k is None:\n",
        "        k = sorted_sim.shape[1]\n",
        "\n",
        "    # find candidate items\n",
        "    user_item_ids, candidates = candidate_items(norm_ratings, user_id, k, sorted_sim, neighbors, item_mapping, inv_item_mapping)\n",
        "    \n",
        "    # rank candidate items according to their similarities with user_item_ids\n",
        "    ranked_candidates = rank_candidates(norm_ratings, user_id, candidates, user_item_ids, distance_matrix, item_mapping)\n",
        "    \n",
        "    # get the first N row of ranked_candidates to build the top N recommendation list\n",
        "    top_n = pl.from_records(ranked_candidates[:N], schema={\"item_id\": norm_ratings.schema[\"item_id\"], \"sim\": pl.Float32})\n",
        "\n",
        "    return top_n.join(items.select(pl.col(\"item_id\"), pl.col(\"title\")), on=\"item_id\", how=\"inner\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi1AmzvzHXMw"
      },
      "source": [
        "Посмотрим, как это работает:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "rec = topn_recommendation(norm_ratings, items, 1, distances, sorted_sim, neighbors, item_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (10, 3)\n",
            "┌─────────┬──────────┬─────────────────────────────────────────────────────────────────────────────┐\n",
            "│ item_id ┆ sim      ┆ title                                                                       │\n",
            "│ ---     ┆ ---      ┆ ---                                                                         │\n",
            "│ u32     ┆ f32      ┆ str                                                                         │\n",
            "╞═════════╪══════════╪═════════════════════════════════════════════════════════════════════════════╡\n",
            "│ 1       ┆ 4.348933 ┆ Toy Story (1995)                                                            │\n",
            "│ 297     ┆ 4.400891 ┆ Ulee's Gold (1997)                                                          │\n",
            "│ 318     ┆ 4.380766 ┆ Schindler's List (1993)                                                     │\n",
            "│ 357     ┆ 4.377169 ┆ One Flew Over the Cuckoo's Nest (1975)                                      │\n",
            "│ …       ┆ …        ┆ …                                                                           │\n",
            "│ 443     ┆ 4.352633 ┆ Birds, The (1963)                                                           │\n",
            "│ 474     ┆ 4.361219 ┆ Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963) │\n",
            "│ 479     ┆ 4.36959  ┆ Vertigo (1958)                                                              │\n",
            "│ 483     ┆ 4.401899 ┆ Casablanca (1942)                                                           │\n",
            "└─────────┴──────────┴─────────────────────────────────────────────────────────────────────────────┘\n"
          ]
        }
      ],
      "source": [
        "with pl.Config() as config:\n",
        "    config.set_fmt_str_lengths(200)\n",
        "    print(rec.head(n=10))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9thC1LQtHMNT"
      },
      "source": [
        "А теперь попробуем применить то, что у нас получилось на тестовом пользователе, для которого соберём историю просмотров сами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "vHvdh9tSHgtM"
      },
      "outputs": [],
      "source": [
        "user_id = 2\n",
        "test_hist = norm_ratings.filter(pl.col(\"user_id\") == user_id).sample(fraction=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "rec = topn_recommendation(test_hist, items, user_id, distances, sorted_sim, neighbors, item_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (6, 6)\n",
            "┌─────────┬─────────┬────────┬──────────────────┬─────────────┬────────────────────────────────┐\n",
            "│ user_id ┆ item_id ┆ rating ┆ mean_user_rating ┆ norm_rating ┆ title                          │\n",
            "│ ---     ┆ ---     ┆ ---    ┆ ---              ┆ ---         ┆ ---                            │\n",
            "│ u32     ┆ u32     ┆ f32    ┆ f32              ┆ f32         ┆ str                            │\n",
            "╞═════════╪═════════╪════════╪══════════════════╪═════════════╪════════════════════════════════╡\n",
            "│ 2       ┆ 25      ┆ 4.0    ┆ 3.709677         ┆ 0.290323    ┆ Birdcage, The (1996)           │\n",
            "│ 2       ┆ 111     ┆ 4.0    ┆ 3.709677         ┆ 0.290323    ┆ Truth About Cats & Dogs, The   │\n",
            "│         ┆         ┆        ┆                  ┆             ┆ (1996)                         │\n",
            "│ 2       ┆ 272     ┆ 5.0    ┆ 3.709677         ┆ 1.290323    ┆ Good Will Hunting (1997)       │\n",
            "│ 2       ┆ 284     ┆ 4.0    ┆ 3.709677         ┆ 0.290323    ┆ Tin Cup (1996)                 │\n",
            "│ 2       ┆ 307     ┆ 3.0    ┆ 3.709677         ┆ -0.709677   ┆ Devil's Advocate, The (1997)   │\n",
            "│ 2       ┆ 308     ┆ 3.0    ┆ 3.709677         ┆ -0.709677   ┆ FairyTale: A True Story (1997) │\n",
            "└─────────┴─────────┴────────┴──────────────────┴─────────────┴────────────────────────────────┘ shape: (10, 3)\n",
            "┌─────────┬──────────┬────────────────────────────────┐\n",
            "│ item_id ┆ sim      ┆ title                          │\n",
            "│ ---     ┆ ---      ┆ ---                            │\n",
            "│ u32     ┆ f32      ┆ str                            │\n",
            "╞═════════╪══════════╪════════════════════════════════╡\n",
            "│ 9       ┆ 4.450466 ┆ Dead Man Walking (1995)        │\n",
            "│ 15      ┆ 4.56404  ┆ Mr. Holland's Opus (1995)      │\n",
            "│ 42      ┆ 4.471148 ┆ Clerks (1994)                  │\n",
            "│ 66      ┆ 4.461242 ┆ While You Were Sleeping (1995) │\n",
            "│ …       ┆ …        ┆ …                              │\n",
            "│ 126     ┆ 4.58197  ┆ Spitfire Grill, The (1996)     │\n",
            "│ 144     ┆ 4.591296 ┆ Die Hard (1988)                │\n",
            "│ 150     ┆ 4.483635 ┆ Swingers (1996)                │\n",
            "│ 153     ┆ 4.560037 ┆ Fish Called Wanda, A (1988)    │\n",
            "└─────────┴──────────┴────────────────────────────────┘\n"
          ]
        }
      ],
      "source": [
        "with pl.Config() as config:\n",
        "    config.set_fmt_str_lengths(200)\n",
        "    \n",
        "    print(test_hist.join(items, on=\"item_id\", how=\"inner\"), rec.head(n=10))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nslAYvmaQtvW"
      },
      "source": [
        "Итак, в этом семинаре мы научились строить item-to-item рекомендации. Этот подход можно улучшать и развивать. \n",
        "\n",
        "1. Например, мы можем учитывать рейтинги айтемов из истории пользователя. Определить, когда рейтинг был позитивный и учитывать кандидатов только для таких айтемов\n",
        "2. Можем поэксеприментировать над определением похожести"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "notebookId": "fb2355fb-9f81-4225-8cbd-6f57bd3092a1",
    "notebookPath": "recsys/1/seminar.ipynb"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
